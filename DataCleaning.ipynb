{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###                ###\n",
    "### Data Cleaning  ###\n",
    "###                ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd   - Tratamiento de datos\n",
    "# import numpy as np    - Biblioteca numerica de python\n",
    "# import seaborn as sns - Graficas basadas en Matplotlib\n",
    "# import datetime       - Manejo y tratamiento de Fechas\n",
    "# import chardet        - Modulo de Encoding para caracteres\n",
    "\n",
    "# Dataset Derrumbes By NASA (https://www.kaggle.com/nasa/landslide-events)\n",
    "# Dataset Terremotos By Us Geological Survey (https://www.kaggle.com/usgs/earthquake-database)\n",
    "# Dataset Fifa By Karan Gadiya (https://www.kaggle.com/karangadiya/fifa19/)\n",
    "# Dataset Adult By Ronny Kohavi and Barry Becker (http://archive.ics.uci.edu/ml/datasets/Adult)\n",
    "# Dataset Kickstarter By Mickaël Mouillé obtained with Kickstarter Platform API (https://www.kaggle.com/kemical/kickstarter-projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np   \n",
    "import seaborn as sns \n",
    "import datetime\n",
    "import chardet\n",
    "\n",
    "# Leer Datasets  (Pandas)\n",
    "pd.__version__\n",
    "earthquakes = pd.read_csv('databases/terremotos.csv')\n",
    "derrumbes = pd.read_csv('databases/derrumbes.csv')\n",
    "fifa = pd.read_csv('databases/fifa.csv')\n",
    "fifaM = pd.read_csv('databases/fifaM.csv')\n",
    "adult = pd.read_csv('databases/adult.csv')\n",
    "chavos_prepa = pd.read_csv('databases/snsdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0        id         date_opened     total\n",
      "0            1  A880C79F          2003-10-19    169305\n",
      "1            2  BE8222DF    October 05, 2018    107460\n",
      "2            3  19F9E113          2008-07-29  15297152\n",
      "3            4  A2FE52A3          2005-06-09  14897272\n",
      "4            5  F6DC2C08          2012-03-31    124568\n",
      "..         ...       ...                 ...       ...\n",
      "93          94  65EAC615   February 20, 2004    140191\n",
      "94          95  6C7509C9  September 16, 2000    212089\n",
      "95          96  BD969A9D          2007-04-29    167238\n",
      "96          97  B0CDCE3D        May 28, 2014    145240\n",
      "97          98  33A7F03E    October 14, 2007    191839\n",
      "\n",
      "[98 rows x 4 columns]\n",
      "0    2003-10-19\n",
      "1    2018-10-05\n",
      "2    2008-07-29\n",
      "3    2005-06-09\n",
      "4    2012-03-31\n",
      "        ...    \n",
      "93   2004-02-20\n",
      "94   2000-09-16\n",
      "95   2007-04-29\n",
      "96   2014-05-28\n",
      "97   2007-10-14\n",
      "Name: date_opened_parsed, Length: 98, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Manejo y transformación de Fechas\n",
    "# Vamos a utilizar para las fehcas datasets con terremoetos entre 1965 y 2016 y con Derrumbes enre 2007 y 2016\n",
    "\n",
    "#print(earthquakes)\n",
    "#print(derrumbes)\n",
    "\n",
    "\n",
    "# Checar Tipo de Dato de la columna fecha en los derrumbes\n",
    "#print(derrumbes['date'].head())\n",
    "\n",
    "# dtype: object PAndas usa el Object para referirse a varios tipos de datos pero normalmente son strings\n",
    "derrumbes['date'].dtype\n",
    "\n",
    "# Transformar a fechas de a devis\n",
    "derrumbes['date_parsed'] = pd.to_datetime(derrumbes['date'], format = \"%m/%d/%y\")\n",
    "#print(derrumbes['date_parsed'].head())\n",
    "#print(derrumbes)\n",
    "\n",
    "# Notilla extra, si en la columna a parsear hay varios tipos de formato de fecha, mejor decirle al python que la infiera\n",
    "# landslides['date_parsed'] = pd.to_datetime(landslides['Date'], infer_datetime_format=True)\n",
    "\n",
    "dia_del_mes_derrumbes = derrumbes['date_parsed'].dt.day\n",
    "#print(dia_del_mes_derrumbes)\n",
    "\n",
    "# Grafiquemos para double-check\n",
    "# doesn't hurt to double-check that the days of the month we've extracted make sense.\n",
    "\n",
    "dia_del_mes_derrumbes = dia_del_mes_derrumbes.dropna()\n",
    "#sns.histplot(dia_del_mes_derrumbes, kde=False, bins=31)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Que pasa si la fecha de un Dataset viene en varios Formatos???\n",
    "\n",
    "accounts = pd.read_csv('databases/accounts.csv')\n",
    "print(accounts)\n",
    "accounts['date_opened_parsed'] = pd.to_datetime(accounts['date_opened'], infer_datetime_format=True)\n",
    "print(accounts['date_opened_parsed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the euro symbol: €\n"
     ]
    }
   ],
   "source": [
    "# Remover y reemplazar  y modificar caracteres no deseados\n",
    "\n",
    "#adult\n",
    "#adult.info()\n",
    "\n",
    "adult[' Male'] = adult[' Male'].str.replace(' ', '')\n",
    "#adult[' Male']\n",
    "\n",
    "#fifa\n",
    "\n",
    "#fifa.info()\n",
    "\n",
    "#fifa['Wage']\n",
    "\n",
    "fifa['wage_trimmed'] = fifa['Wage'].str.translate({ord(i): None for i in '€K'})\n",
    "fifa['wage_numeric'] = fifa['wage_trimmed'].astype(int) * 1000\n",
    "fifa['wage_trimmed'] = fifa['Wage'].replace('€', '')\n",
    "#print(fifa['wage_trimmed'].head(10), fifa['wage_numeric'].head(10))\n",
    "#fifa\n",
    "\n",
    "\n",
    "fifaM\n",
    "fifaM['Release.Clause'] = fifaM['Release.Clause'].str.translate({ord('€'): None})\n",
    "fifaM['Release.Clause'] = fifaM['Release.Clause'].str.replace('K', '000')\n",
    "fifaM['Release.Clause'] = fifaM['Release.Clause'].str.replace('M', '000000')\n",
    "\n",
    "#print(fifaM['Release.Clause'])\n",
    "\n",
    "\n",
    "# Que bueno que fifa traía el simbolo de Euro como simbolo de Euro, no? Pero. qué pasa si el dataset tiene algo como esto:\n",
    "# æ–‡å—åŒ–ã?? o ����������\n",
    "\n",
    "##  What Are encodings???? ##\n",
    "\n",
    "# Character encodings are specific sets of rules for mapping from raw binary byte strings \n",
    "# (that look like this: 0110100001101001) to characters that make up human-readable text (like \"hi\")\n",
    "# UTF-8 is the standard text encoding. All Python code is in UTF-8 and, ideally, all your data should be as well. \n",
    "# It's when things aren't in UTF-8 that you run into trouble.\n",
    "\n",
    "\n",
    "\n",
    "before = \"This is the euro symbol: €\"\n",
    "type(before)\n",
    "\n",
    "\n",
    "after = before.encode(\"utf-8\", errors = \"replace\")\n",
    "\n",
    "type(after)\n",
    "after\n",
    "print(after.decode(\"utf-8\"))\n",
    "#print(after.decode(\"ascii\"))\n",
    "\n",
    "\n",
    "\n",
    "before = \"This is the euro symbol: €\"\n",
    "\n",
    "# encode it to a different encoding, replacing characters that raise errors\n",
    "after = before.encode(\"ascii\", errors = \"replace\")\n",
    "\n",
    "# convert it back to utf-8\n",
    "#print(after.decode(\"ascii\"))\n",
    "\n",
    "# The best time to convert non UTF-8 input into UTF-8 is when you read in files,\n",
    "\n",
    "\n",
    "#kickstarter_2016 = pd.read_csv(\"databases/kickstarter-encoding.csv\")\n",
    "\n",
    "\n",
    "with open(\"databases/PoliceKillingsUS.csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(100000))\n",
    "    \n",
    "#print(result)\n",
    "Police_Killing = pd.read_csv(\"databases/PoliceKillingsUS.csv\", encoding='Windows-1252')\n",
    "#kickstarter_2016 = pd.read_csv(\"databases/kickstarter-encoding.csv\", encoding='Windows-1252')\n",
    "#kickstarter_2016.head()\n",
    "#Police_Killing.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# Valores Fuera de Rango y valores perdidos\n",
    "\n",
    "chavos_prepa = pd.read_csv('databases/snsdata.csv')\n",
    "#chavos_prepa.info()\n",
    "chavos_prepa.describe(include='all')\n",
    "chavos_prepa\n",
    "\n",
    "# Vamos a ver cuantos Valores NA tenemos en nuestra columna de Age\n",
    "missing_values_age_count = chavos_prepa['age'].isnull().sum()\n",
    "#print(missing_values_age_count)\n",
    "number_of_rows = len(chavos_prepa)\n",
    "#print(number_of_rows)\n",
    "#print('Porcentaje total de Edades perdidas en el dataset es:', (missing_values_age_count/number_of_rows) *100)\n",
    "\n",
    "#chavos_prepa['age'].dropna()\n",
    "\n",
    "chavos_prepa['age_filled'] = np.where(chavos_prepa['age'].isnull(), np.mean(chavos_prepa['age']), chavos_prepa['age'])\n",
    "\n",
    "chavos_prepa_count = chavos_prepa['age_filled'].isnull().sum()\n",
    "#print(chavos_prepa_count)\n",
    "\n",
    "## Crearemos un histograma para identificar valores fuera de rango\n",
    "# Creamos los cortes\n",
    "min_teen_age = 12\n",
    "max_teen_age = 21\n",
    "#sns.histplot(chavos_prepa['age_filled'], kde=True, bins=int(np.max(chavos_prepa['age_filled'])))\n",
    "\n",
    "\n",
    "# Reemplazamos las edades por encima del rango con la edad máxima\n",
    "\n",
    "chavos_prepa['age_filled'] = np.where(chavos_prepa['age_filled'] > max_teen_age, max_teen_age, chavos_prepa['age_filled'])\n",
    "\n",
    "print(int(np.max(chavos_prepa['age_filled'])))\n",
    "#sns.histplot(chavos_prepa['age_filled'], kde=True, bins=int(np.max(chavos_prepa['age_filled'])))\n",
    "\n",
    "# Reemplazamos las edades por debajo del rango con la edad mínima\n",
    "\n",
    "chavos_prepa['age_filled'] = np.where(chavos_prepa['age_filled'] < min_teen_age, min_teen_age, chavos_prepa['age_filled'])\n",
    "\n",
    "print(int(np.min(chavos_prepa['age_filled'])))\n",
    "#sns.histplot(chavos_prepa['age_filled'], kde=False, bins=int(np.max(chavos_prepa['age_filled'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uniformidad en tipo de cambio\n",
    "#  Vamos a ver para que nos va a servir la base anterior\n",
    "\n",
    "accounts\n",
    "\n",
    "#sns.scatterplot(data=accounts, x=\"date_opened_parsed\", y=\"total\")\n",
    "\n",
    "\n",
    "# The formula to convert yen to dollars is USD = JPY / 104.\n",
    "\n",
    "account_offices = pd.read_csv('databases/account_offices.csv')\n",
    "\n",
    "#account_offices.info()\n",
    "account_offices\n",
    "#accounts\n",
    "\n",
    "accounts_global = pd.merge(accounts, account_offices, on=\"id\")\n",
    "#print(accounts_global)\n",
    "accounts_global['total_usd'] = np.where(accounts_global['office'] == 'Tokyo', accounts_global['total'] / 104, accounts_global['total'])\n",
    "#print(accounts_global)\n",
    "\n",
    "#sns.scatterplot(data=accounts_global, x=\"date_opened_parsed\", y=\"total_usd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column1</th>\n",
       "      <th>column2</th>\n",
       "      <th>column3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d</td>\n",
       "      <td>f</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>3000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  column1 column2  column3\n",
       "0       a       b     1000\n",
       "2       d       f     4500\n",
       "4       b       b     3000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checar datos duplicados\n",
    "letters = pd.read_csv('databases/letters.csv')\n",
    "letters\n",
    "letters.duplicated()\n",
    "sum(letters.duplicated())\n",
    "letters\n",
    "\n",
    "# Remover duplicados totales\n",
    "\n",
    "letters.drop_duplicates()\n",
    "# sum(letters.duplicated())\n",
    "letters\n",
    "letters = letters.drop_duplicates()\n",
    "#sum(letters.duplicated())\n",
    "\n",
    "\n",
    "# Weno weno, pero y los duplicados de 1 sola columna???\n",
    "letters = pd.read_csv('databases/letters.csv')\n",
    "letters\n",
    "letters.rename(columns={\"column1\": \"alumno\", \"column2\": \"curso\", \"column3\": \"pago\"})\n",
    "#letters\n",
    "letters.drop_duplicates(subset=['column1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
