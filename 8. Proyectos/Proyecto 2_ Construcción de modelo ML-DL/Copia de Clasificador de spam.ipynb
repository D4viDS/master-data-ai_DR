{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de Clasificador de spam.ipynb","provenance":[{"file_id":"1Wr9LEaqf7KVHH964LZ74KDv9CKOBc2t8","timestamp":1643329710384}],"collapsed_sections":[],"authorship_tag":"ABX9TyP58ig04s3oW6yO/NDkrbwV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Proyectos de Machine Learning - Proyecto II\n","En esta sección vamos desarrollar agentes inteligentes para la detección de mensajes de spam."],"metadata":{"id":"j_qia0PgB9uf"}},{"cell_type":"markdown","source":["1. Spam classification\n","In this problem, we will use the Naive Bayes algorithm and an SVM to build a spam classifier.\n","In recent years, spam on electronic media has been a growing concern. Here, we’ll build a classifier to distinguish between real messages, and spam messages. For this class, we will be building a classifier to detect SMS spam messages. We will be using an SMS spam dataset developed by Tiago A. Almedia and Jose Marıa Gomez Hidalgo which is publicly available on http://www.dt.fee.unicamp.br/~tiago/smsspamcollection\n","We have split this dataset into training and testing sets and have included them in this assignment as:\n","\n","* src-spam/spam train.tsv\n","* src-spam/spam test.tsv\n","\n","See src-spam/spam readme.txt for more details about this dataset. Please refrain from redistributing these dataset files. The goal of this assignment is to build a classifier from scratch that can tell the difference the spam and non-spam messages using the text of the SMS message.\n"],"metadata":{"id":"xMM2JwTABlVA"}},{"cell_type":"code","source":["#@title Importamos utilerias\n","import csv\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import json\n","\n","\n","def add_intercept_fn(x):\n","    \"\"\"Add intercept to matrix x.\n","\n","    Args:\n","        x: 2D NumPy array.\n","\n","    Returns:\n","        New matrix same as x with 1's in the 0th column.\n","    \"\"\"\n","    new_x = np.zeros((x.shape[0], x.shape[1] + 1), dtype=x.dtype)\n","    new_x[:, 0] = 1\n","    new_x[:, 1:] = x\n","\n","    return new_x\n","\n","def load_csv(csv_path, label_col='y', add_intercept=False):\n","    \"\"\"Load dataset from a CSV file.\n","\n","    Args:\n","         csv_path: Path to CSV file containing dataset.\n","         label_col: Name of column to use as labels (should be 'y' or 'l').\n","         add_intercept: Add an intercept entry to x-values.\n","\n","    Returns:\n","        xs: Numpy array of x-values (inputs).\n","        ys: Numpy array of y-values (labels).\n","    \"\"\"\n","\n","    # Load headers\n","    with open(csv_path, 'r', newline='') as csv_fh:\n","        headers = csv_fh.readline().strip().split(',')\n","\n","    # Load features and labels\n","    x_cols = [i for i in range(len(headers)) if headers[i].startswith('x')]\n","    l_cols = [i for i in range(len(headers)) if headers[i] == label_col]\n","    inputs = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=x_cols)\n","    labels = np.loadtxt(csv_path, delimiter=',', skiprows=1, usecols=l_cols)\n","\n","    if inputs.ndim == 1:\n","        inputs = np.expand_dims(inputs, -1)\n","\n","    if add_intercept:\n","        inputs = add_intercept_fn(inputs)\n","\n","    return inputs, labels\n","\n","def load_spam_dataset(tsv_path):\n","    \"\"\"Load the spam dataset from a TSV file\n","\n","    Args:\n","         tsv_path: Path to TSV file containing dataset.\n","\n","    Returns:\n","        messages: A list of string values containing the text of each message.\n","        labels: The binary labels (0 or 1) for each message. A 1 indicates spam.\n","    \"\"\"\n","\n","    messages = []\n","    labels = []\n","\n","    with open(tsv_path, 'r', newline='', encoding='utf8') as tsv_file:\n","        reader = csv.reader(tsv_file, delimiter='\\t', quoting=csv.QUOTE_NONE)\n","\n","        for label, message in reader:\n","            messages.append(message)\n","            labels.append(1 if label == 'spam' else 0)\n","\n","    return messages, np.array(labels)\n","\n","def plot(x, y, theta, save_path, correction=1.0):\n","    \"\"\"Plot dataset and fitted logistic regression parameters.\n","\n","    Args:\n","        x: Matrix of training examples, one per row.\n","        y: Vector of labels in {0, 1}.\n","        theta: Vector of parameters for logistic regression model.\n","        save_path: Path to save the plot.\n","        correction: Correction factor to apply (Problem 2(e) only).\n","    \"\"\"\n","    # Plot dataset\n","    plt.figure()\n","    plt.plot(x[y == 1, -2], x[y == 1, -1], 'bx', linewidth=2)\n","    plt.plot(x[y == 0, -2], x[y == 0, -1], 'go', linewidth=2)\n","\n","    # Plot decision boundary (found by solving for theta^T x = 0)\n","    x1 = np.arange(min(x[:, -2]), max(x[:, -2]), 0.01)\n","    x2 = -(theta[0] / theta[2] * correction + theta[1] / theta[2] * x1)\n","    plt.plot(x1, x2, c='red', linewidth=2)\n","\n","    # Add labels and save to disk\n","    plt.xlabel('x1')\n","    plt.ylabel('x2')\n","    plt.savefig(save_path)\n","\n","\n","def plot_contour(predict_fn):\n","    \"\"\"Plot a contour given the provided prediction function\"\"\"\n","    x, y = np.meshgrid(np.linspace(-10, 10, num=20), np.linspace(-10, 10, num=20))\n","    z = np.zeros(x.shape)\n","\n","    for i in range(x.shape[0]):\n","        for j in range(y.shape[1]):\n","            z[i, j] = predict_fn([x[i, j], y[i, j]])\n","\n","    plt.contourf(x, y, z, levels=[-float('inf'), 0, float('inf')], colors=['orange', 'cyan'])\n","\n","def plot_points(x, y):\n","    \"\"\"Plot some points where x are the coordinates and y is the label\"\"\"\n","    x_one = x[y == 0, :]\n","    x_two = x[y == 1, :]\n","\n","    plt.scatter(x_one[:,0], x_one[:,1], marker='x', color='red')\n","    plt.scatter(x_two[:,0], x_two[:,1], marker='o', color='blue')\n","\n","def write_json(filename, value):\n","    \"\"\"Write the provided value as JSON to the given filename\"\"\"\n","    with open(filename, 'w') as f:\n","        json.dump(value, f)\n"],"metadata":{"id":"obD159cBwCMv","executionInfo":{"status":"ok","timestamp":1643328929108,"user_tz":360,"elapsed":306,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#@title Importamos SVM\n","# Important note: you do not have to modify this file for your homework.\n","\n","import numpy as np\n","np.random.seed(123)\n","\n","\n","def train_and_predict_svm(train_matrix, train_labels, test_matrix, radius):\n","    \"\"\"Train an SVM model and predict the resulting labels on a test set.\n","\n","    Args:\n","        train_matrix: A numpy array containing the word counts for the train set\n","        train_labels: A numpy array containing the spam or not spam labels for the train set\n","        test_matrix: A numpy array containing the word counts for the test set\n","        radius: The RBF kernel radius to use for the SVM\n","\n","    Return:\n","        The predicted labels for each message\n","    \"\"\"\n","    model = svm_train(train_matrix, train_labels, radius)\n","    return svm_predict(model, test_matrix, radius)\n","\n","\n","def svm_train(matrix, category, radius):\n","    state = {}\n","    M, N = matrix.shape\n","    Y = 2 * category - 1\n","    matrix = 1. * (matrix > 0)\n","    squared = np.sum(matrix * matrix, axis=1)\n","    gram = matrix.dot(matrix.T)\n","    K = np.exp(-(squared.reshape((1, -1)) + squared.reshape((-1, 1)) - 2 * gram) / (2 * (radius ** 2)))\n","\n","    alpha = np.zeros(M)\n","    alpha_avg = np.zeros(M)\n","    L = 1. / (64 * M)\n","    outer_loops = 10\n","\n","    alpha_avg = 0\n","    ii = 0\n","    while ii < outer_loops * M:\n","        i = int(np.random.rand() * M)\n","        margin = Y[i] * np.dot(K[i, :], alpha)\n","        grad = M * L * K[:, i] * alpha[i]\n","        if margin < 1:\n","            grad -= Y[i] * K[:, i]\n","        alpha -= grad / np.sqrt(ii + 1)\n","        alpha_avg += alpha\n","        ii += 1\n","\n","    alpha_avg /= (ii + 1) * M\n","\n","    state['alpha'] = alpha\n","    state['alpha_avg'] = alpha_avg\n","    state['Xtrain'] = matrix\n","    state['Sqtrain'] = squared\n","    return state\n","\n","\n","def svm_predict(state, matrix, radius):\n","    M, N = matrix.shape\n","\n","    Xtrain = state['Xtrain']\n","    Sqtrain = state['Sqtrain']\n","    matrix = 1. * (matrix > 0)\n","    squared = np.sum(matrix * matrix, axis=1)\n","    gram = matrix.dot(Xtrain.T)\n","    K = np.exp(-(squared.reshape((-1, 1)) + Sqtrain.reshape((1, -1)) - 2 * gram) / (2 * (radius ** 2)))\n","    alpha_avg = state['alpha_avg']\n","    preds = K.dot(alpha_avg)\n","    output = (1 + np.sign(preds)) // 2\n","\n","    return output\n"],"metadata":{"cellView":"form","id":"QgTefrWhyGF1","executionInfo":{"status":"ok","timestamp":1643328891182,"user_tz":360,"elapsed":7,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Instrucciones - Proyecto II\n","\n","(a) Implement code for processing the the spam messages into numpy arrays that can be fed into machine learning models. Do this by completing the get_words(), create_dictionary(), and transform_text() functions within our provided src-spam/submission.py. Do note the corresponding comments for each function for instructions on what specific processing is required. The autograder test case 1a-4-basic will then run your functions and save the resulting dictionary into spam_dictionary and a sample of the resulting training matrix into spam_sample_train_matrix_(soln).\n","\n"],"metadata":{"id":"d5ily8YiEMig"}},{"cell_type":"markdown","source":["(b) In this question you are going to implement a Naive Bayes classifier for spam classification with multinomial event model and Laplace smoothing.\n","\n","Code your implementation by completing the fit_naive_bayes_model() and predict_from_naive_bayes_model() func- tions in src-spam/submission.py.\n","\n","Now the functions in src-spam/submission.py should be able to train a Naive Bayes model. Use autograder test case 1b-1-basic to compute your prediction accuracy and then save your resulting predictions to spam_naive_bayes_predictions_(soln).\n","\n","Remark. If you implement Naive Bayes the straightforward way, you will find that the computed p(x|y) = 􏰆i p(xi|y) often equals zero. This is because p(x|y), which is the product of many numbers less than one, is a very small number. The standard computer representation of real numbers cannot handle numbers that are too small, and instead rounds them off to zero. (This is called “underflow.”) You’ll have to find a way to compute Naive Bayes’ predicted class labels without explicitly representing very small numbers such as p(x|y). Hint: Think about using logarithms."],"metadata":{"id":"F8hFBfTzER76"}},{"cell_type":"markdown","source":["(c) Intuitively, some tokens may be particularly indicative of an SMS being in a particular class. We can try to get an informal sense of how indicative token i is for the SPAM class by looking at:\n","\n","IMAGE GOES HERE\n","\n","Complete the get_top_five_naive_bayes_words() function within the provided code using the above formula. Run autograder test case 1c-1-basic to obtain the 5 most indicative tokens.\n"],"metadata":{"id":"9BDrQw83ESMR"}},{"cell_type":"markdown","source":["(d) Support vector machines (SVMs) are an alternative machine learning model that we discussed in class. We have provided you an SVM implementation (using a radial basis function (RBF) kernel) within src-spam/svm.py (You should not need to modify that code).\n","\n","One important part of training an SVM parameterized by an RBF kernel (a.k.a Gaussian kernel) is choosing an appropriate kernel radius parameter.\n","\n","Complete the compute_best_svm_radius() by writing code to compute the best SVM radius which maximizes accuracy on the validation dataset."],"metadata":{"id":"tAAjfb0PESY0"}},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":346},"id":"nICDVgz-BdVf","executionInfo":{"status":"error","timestamp":1643328931959,"user_tz":360,"elapsed":506,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}},"outputId":"ecfcf56f-db7d-4a8f-f118-445ef431317d"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-74a554bf86af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-17-74a554bf86af>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mtrain_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_spam_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spam_train.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mval_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_spam_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spam_val.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mtest_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_spam_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'spam_test.tsv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-da921297ba1e>\u001b[0m in \u001b[0;36mload_spam_dataset\u001b[0;34m(tsv_path)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_NONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spam_train.tsv'"]}],"source":["import collections\n","\n","import numpy as np\n","\n","\n","def get_words(message):\n","    \"\"\"Get the normalized list of words from a message string.\n","\n","    This function should split a message into words, normalize them, and return\n","    the resulting list. For splitting, you should split on spaces. For normalization,\n","    you should convert everything to lowercase.\n","\n","    Note for enterprising students:  There are myriad ways to split sentences for\n","    this algorithm.  For instance, you might want to exclude punctuation (unless\n","    it's organized in an email address format) or exclude numbers (unless they're\n","    organized in a zip code or phone number format).  Clearly this can become quite\n","    complex.  For our purposes, please split using the space character ONLY.  This\n","    is intended to balance your understanding with our ability to autograde the\n","    assignment.  Thanks and have fun with the rest of the assignment!\n","\n","    Args:\n","        message: A string containing an SMS message\n","\n","    Returns:\n","       The list of normalized words from the message.\n","    \"\"\"\n","\n","    # *** START CODE HERE ***\n","    \n","    # *** END CODE HERE ***\n","\n","\n","def create_dictionary(messages):\n","    \"\"\"Create a dictionary mapping words to integer indices.\n","\n","    This function should create a dictionary of word to indices using the provided\n","    training messages. Use get_words to process each message.\n","\n","    Rare words are often not useful for modeling. Please only add words to the dictionary\n","    if they occur in at least *five messages*.\n","\n","    Args:\n","        messages: A list of strings containing SMS messages\n","\n","    Returns:\n","        A python dict mapping words to integers.\n","    \"\"\"\n","\n","    # *** START CODE HERE ***\n","        \n","    word_dict = {}\n","    for message in messages:\n","        word_list = get_words(message)\n","        for word in word_list:\n","            if word in word_dict:\n","                word_dict[word] += 1\n","            else:\n","                word_dict[word] = 1\n","        \n","    index = 0\n","    for word_key in list(word_dict.keys()):\n","        if word_dict[word_key] >= 5:\n","            word_dict[word_key] = index\n","            index += 1\n","        else:\n","            del word_dict[word_key]\n","    return word_dict\n","    \n","    # *** END CODE HERE ***\n","\n","\n","def transform_text(messages, word_dictionary):\n","    \"\"\"Transform a list of text messages into a numpy array for further processing.\n","\n","    This function should create a numpy array that contains the number of times each word\n","    of the vocabulary appears in each message.\n","    Each row in the resulting array should correspond to each message\n","    and each column should correspond to *a word of the vocabulary*.\n","\n","    Use the provided word dictionary to map words to column indices. Ignore words that\n","    are not present in the dictionary. Use get_words to get the words for a message.\n","\n","    Args:\n","        messages: A list of strings where each string is an SMS message.\n","        word_dictionary: A python dict mapping words to integers.\n","\n","    Returns:\n","        A numpy array marking the words present in each message.\n","        Where the component (i,j) is the number of occurrences of the\n","        j-th vocabulary word in the i-th message.\n","    \"\"\"\n","    # *** START CODE HERE ***\n","    \n","    word_num = len(word_dictionary)\n","    word_array = np.array([]).reshape(0, word_num)\n","    for message in messages:\n","        word_list = get_words(message)\n","        word_count = np.zeros((1, word_num))\n","        for word in word_list:\n","            if word in word_dictionary:\n","                word_count[0, word_dictionary[word]] += 1\n","        word_array = np.vstack([word_array, word_count])\n","    return word_array\n","\n","    # *** END CODE HERE ***\n","\n","\n","def fit_naive_bayes_model(matrix, labels):\n","    \"\"\"Fit a naive bayes model.\n","\n","    This function should fit a Naive Bayes model given a training matrix and labels.\n","\n","    The function should return the state of that model.\n","\n","    Feel free to use whatever datatype you wish for the state of the model.\n","\n","    Args:\n","        matrix: A numpy array containing word counts for the training data\n","        labels: The binary (0 or 1) labels for that training data\n","\n","    Returns: The trained model\n","    \"\"\"\n","\n","    # *** START CODE HERE ***\n","\n","    # *** END CODE HERE ***\n","\n","\n","def predict_from_naive_bayes_model(model, matrix):\n","    \"\"\"Use a Naive Bayes model to compute predictions for a target matrix.\n","\n","    This function should be able to predict on the models that fit_naive_bayes_model\n","    outputs.\n","\n","    Args:\n","        model: A trained model from fit_naive_bayes_model\n","        matrix: A numpy array containing word counts\n","\n","    Returns: A numpy array containing the predictions from the model\n","    \"\"\"\n","    # *** START CODE HERE ***\n","\n","    # *** END CODE HERE ***\n","\n","\n","def get_top_five_naive_bayes_words(model, dictionary):\n","    \"\"\"Compute the top five words that are most indicative of the spam (i.e positive) class.\n","\n","    Ues the metric given in part-c as a measure of how indicative a word is.\n","    Return the words in sorted form, with the most indicative word first.\n","\n","    Args:\n","        model: The Naive Bayes model returned from fit_naive_bayes_model\n","        dictionary: A mapping of word to integer ids\n","\n","    Returns: A list of the top five most indicative words in sorted order with the most indicative first\n","    \"\"\"\n","    # *** START CODE HERE ***\n","\n","    # *** END CODE HERE ***\n","\n","\n","def compute_best_svm_radius(train_matrix, train_labels, val_matrix, val_labels, radius_to_consider):\n","    \"\"\"Compute the optimal SVM radius using the provided training and evaluation datasets.\n","\n","    You should only consider radius values within the radius_to_consider list.\n","    You should use accuracy as a metric for comparing the different radius values.\n","\n","    Args:\n","        train_matrix: The word counts for the training data\n","        train_labels: The spma or not spam labels for the training data\n","        val_matrix: The word counts for the validation data\n","        val_labels: The spam or not spam labels for the validation data\n","        radius_to_consider: The radius values to consider\n","\n","    Returns:\n","        The best radius which maximizes SVM accuracy.\n","    \"\"\"\n","    # *** START CODE HERE ***\n","\n","    # *** END CODE HERE ***\n","\n","\n","def main():\n","    train_messages, train_labels = utils.load_spam_dataset('spam_train.tsv')\n","    val_messages, val_labels = util.load_spam_dataset('spam_val.tsv')\n","    test_messages, test_labels = util.load_spam_dataset('spam_test.tsv')\n","\n","    dictionary = create_dictionary(train_messages)\n","\n","    print('Size of dictionary: ', len(dictionary))\n","\n","    util.write_json('spam_dictionary_(soln)', dictionary)\n","\n","    train_matrix = transform_text(train_messages, dictionary)\n","\n","    np.savetxt('spam_sample_train_matrix_(soln)', train_matrix[:100,:])\n","\n","    val_matrix = transform_text(val_messages, dictionary)\n","    test_matrix = transform_text(test_messages, dictionary)\n","\n","    naive_bayes_model = fit_naive_bayes_model(train_matrix, train_labels)\n","\n","    naive_bayes_predictions = predict_from_naive_bayes_model(naive_bayes_model, test_matrix)\n","\n","    np.savetxt('spam_naive_bayes_predictions_(soln)', naive_bayes_predictions)\n","\n","    naive_bayes_accuracy = np.mean(naive_bayes_predictions == test_labels)\n","\n","    print('Naive Bayes had an accuracy of {} on the testing set'.format(naive_bayes_accuracy))\n","\n","    top_5_words = get_top_five_naive_bayes_words(naive_bayes_model, dictionary)\n","\n","    print('The top 5 indicative words for Naive Bayes are: ', top_5_words)\n","\n","    util.write_json('spam_top_indicative_words_(soln)', top_5_words)\n","\n","    optimal_radius = compute_best_svm_radius(train_matrix, train_labels, val_matrix, val_labels, [0.01, 0.1, 1, 10])\n","\n","    util.write_json('spam_optimal_radius_(soln)', optimal_radius)\n","\n","    print('The optimal SVM radius was {}'.format(optimal_radius))\n","\n","    svm_predictions = svm.train_and_predict_svm(train_matrix, train_labels, test_matrix, optimal_radius)\n","\n","    svm_accuracy = np.mean(svm_predictions == test_labels)\n","\n","    print('The SVM model had an accuracy of {} on the testing set'.format(svm_accuracy, optimal_radius))\n","\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}