{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación y mejoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las formas más comunes para evaluar qué tan bien se desempeña un modelo es utilizar un cross-validation test. Este consiste en entrenar y evaluar a un modelo con distintas partes de la base de datos, tratando de obtener una estimación \"general\" a partir de la estimación de varios modelos.\n",
    "\n",
    "Vamos a ver un ejemplo evaluando un modelo logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris() # Leo base de datos\n",
    "print(iris.data)\n",
    "logreg = LogisticRegression(solver='liblinear', multi_class='ovr') # Importo modelo logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96078431 0.92156863 0.95833333]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=3)\n",
    "print(\"Cross-validation scores: {}\".format(scores)) # Por defaul divide 3 veces la base, \n",
    "                                                    # es decir, hace un \"loop\" 3 veces,\n",
    "                                                    # y nos reporta el accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         0.96666667 0.93333333 0.9        1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Podemos mover el número de folds/grupos moviendo cv\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "print(\"Cross-validation scores: {}\".format(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.96\n"
     ]
    }
   ],
   "source": [
    "#  la medida genral? podemos sacar el promedio de estos 5 \n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [1.         1.         1.         0.93333333 0.93333333 0.93333333\n",
      " 0.8        0.93333333 1.         1.        ]\n",
      "Average cross-validation score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Y con 10 folds?\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=10)\n",
    "print(\"Cross-validation scores: {}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué hacemos si tenemos etiquetas ordenadas en nuestros datos para no entrenar un modelo muy sesgado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris labels:\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "print(\"Iris labels:\\n{}\".format(iris.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.96666667 0.9        0.96666667 0.96666667 0.93333333]\n",
      "Average cross-validation score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# No existe una forma de aplicar un cross-validation estratificado en sklearn, pero podemos hacer un shuffle de observaciones\n",
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=0) \n",
    "print(\"Cross-validation scores:\\n{}\".format(cross_val_score(logreg, iris.data, iris.target, cv=kfold)))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se acuerdan que hablamos de un cross-validation con grupos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:\n",
      "[0.75       0.8        0.66666667]\n",
      "Average cross-validation score: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "# Creamos una base random\n",
    "X, y = make_blobs(n_samples=12, random_state=0)\n",
    "\n",
    "# Asumimos que los grupos en los datos tienen la siguiente distribución \n",
    "groups=[0,0,0,1,1,1,1,2,2,3,3,3]\n",
    "scores = cross_val_score(logreg, X, y, groups, cv=GroupKFold(n_splits=3)) \n",
    "print(\"Cross-validation scores:\\n{}\".format(scores))\n",
    "print(\"Average cross-validation score: {:.2f}\".format(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuál es la forma rupestre de hacer un grid search? Metiendo los parámetros en loops.\n",
    "\n",
    "Hagamos un SVM, donde los parámetros que se pueden mover son gamma (cuando tenemos kernels que no son lineales) y C\n",
    "Se acuerdan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: 112 size of test set: 38\n",
      "Best score: 0.97\n",
      "Best parameters: {'C': 100, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "print(\"Size of training set: {} size of test set: {}\".format(X_train.shape[0], X_test.shape[0]))\n",
    "\n",
    "best_score = 0\n",
    "for gamma in [0.001, 0.01, 0.1, 1, 10, 100]: \n",
    "    for C in [0.001, 0.01, 0.1, 1, 10, 100]:\n",
    "        # entrenar un SVC para cada combinación de parámetros\n",
    "        svm = SVC(gamma=gamma, C=C)\n",
    "        svm.fit(X_train, y_train)\n",
    "        # evaluar el SVC\n",
    "        score = svm.score(X_test, y_test)\n",
    "        # si el score es mejor, guardarlo con los parámetros\n",
    "        if score > best_score: \n",
    "            score = svm.score(X_test, y_test)\n",
    "            best_score = score\n",
    "            best_parameters = {'C': C, 'gamma': gamma}\n",
    "\n",
    "print(\"Best score: {:.2f}\".format(best_score)) \n",
    "print(\"Best parameters: {}\".format(best_parameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al ser una forma tan común, scikit-learn tiene una implementación que nos permite no sólo hacer un grid search, si no combinarlo con un cross validation para que nuestra evaluación sea mucho más completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter grid:\n",
      "{'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Creo primero un diccionario de parámetros a evaluar\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "print(\"Parameter grid:\\n{}\".format(param_grid))\n",
    "\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, iid=True, return_train_score=True) # Le digo que va a hacer 5 folds en el cross-validation, \n",
    "                                                    # y utilizar los parámetros que le di en el diccionario,\n",
    "                                                    # Además de que lo que evaluará es un SVM. \n",
    "                                                    # Es muy importante porque depende el modelo son los parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido mi base\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=None,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hago el grid search con CV\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set score: {:.2f}\".format(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'gamma': 0.01}\n",
      "Best cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Puedo ver cuáles fueron mis mejores parámetros y el merjor score\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator:\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.01, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# También puedo ver cuál fue el modelo completo que mejor ajustó\n",
    "print(\"Best estimator:\\n{}\".format(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.001709      0.000559         0.000601        0.000132   0.001   \n",
      "1       0.001211      0.000303         0.000526        0.000156   0.001   \n",
      "2       0.000962      0.000318         0.000373        0.000163   0.001   \n",
      "3       0.000807      0.000105         0.000374        0.000189   0.001   \n",
      "4       0.000743      0.000007         0.000279        0.000006   0.001   \n",
      "\n",
      "  param_gamma                        params  split0_test_score  \\\n",
      "0       0.001  {'C': 0.001, 'gamma': 0.001}              0.375   \n",
      "1        0.01   {'C': 0.001, 'gamma': 0.01}              0.375   \n",
      "2         0.1    {'C': 0.001, 'gamma': 0.1}              0.375   \n",
      "3           1      {'C': 0.001, 'gamma': 1}              0.375   \n",
      "4          10     {'C': 0.001, 'gamma': 10}              0.375   \n",
      "\n",
      "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
      "0           0.347826           0.363636       ...                0.366071   \n",
      "1           0.347826           0.363636       ...                0.366071   \n",
      "2           0.347826           0.363636       ...                0.366071   \n",
      "3           0.347826           0.363636       ...                0.366071   \n",
      "4           0.347826           0.363636       ...                0.366071   \n",
      "\n",
      "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
      "0        0.011371               22            0.363636            0.370787   \n",
      "1        0.011371               22            0.363636            0.370787   \n",
      "2        0.011371               22            0.363636            0.370787   \n",
      "3        0.011371               22            0.363636            0.370787   \n",
      "4        0.011371               22            0.363636            0.370787   \n",
      "\n",
      "   split2_train_score  split3_train_score  split4_train_score  \\\n",
      "0            0.366667            0.366667            0.362637   \n",
      "1            0.366667            0.366667            0.362637   \n",
      "2            0.366667            0.366667            0.362637   \n",
      "3            0.366667            0.366667            0.362637   \n",
      "4            0.366667            0.366667            0.362637   \n",
      "\n",
      "   mean_train_score  std_train_score  \n",
      "0          0.366079         0.002852  \n",
      "1          0.366079         0.002852  \n",
      "2          0.366079         0.002852  \n",
      "3          0.366079         0.002852  \n",
      "4          0.366079         0.002852  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Podemos ver los resultados desagregados del cross-validation\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "print(results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, mucho cuidado con qué evaluamos. Recuerden que cada cosa que evaluamos ocupa recursos computacionales, y la computadora va a probar lo que nosotros le digamos, sin importantel mucho si lo que nos dice tiene o no sentido.\n",
    "\n",
    "Por ejemplo, en un SVM, si el kernel es lineal, gamma es una constante, por lo que no tendría sentido probar distintos gammas si nuestro kernel es lineal; en cambio si usamos un rbf u otro, sí tiene sentido cambiar gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of grids:\n",
      "[{'kernel': ['rbf'], 'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}, {'kernel': ['linear'], 'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n"
     ]
    }
   ],
   "source": [
    "# Lo que hacemos para solucionar lo anterior es hacer una lista de diccionarios, en vez de un diccionario\n",
    "param_grid = [{'kernel': ['rbf'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "               'gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
    "              {'kernel': ['linear'],\n",
    "               'C': [0.001, 0.01, 0.1, 1, 10, 100]}]\n",
    "\n",
    "print(\"List of grids:\\n{}\".format(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Y ahora sí, podemos probar todo: kernel, parámetros y score\n",
    "grid_search = GridSearchCV(SVC(), param_grid, cv=5, iid=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters: {}\".format(grid_search.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerden que no siempre el \"score\" que nos da el accuracy es lo mejor, hay veces que lo que bucamos es más bien evitar errores tipo 1 o errores tipo 2, por lo que utilizaríamos la precisión o el recall para evaluar mejor nuestro modelo (como lo hablamos en la clase 1).\n",
    "\n",
    "El chiste es sólo cambiar score por lo que necesitemos, que ya hemos visto como sacar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
