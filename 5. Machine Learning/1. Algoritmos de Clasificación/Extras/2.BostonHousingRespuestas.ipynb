{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.4"},"colab":{"name":"2.BostonHousingRespuestas.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"fVFfGuPsB39p"},"source":["# Predicción de Costos de Casas\n","\n","Ahora que tenemos herramientas, es hora de implementar un modelo y evaluarlo. En este proyecto, crearemos predicciones de los costos de las casas de los suburbios de Boston. La idea es crear un modelo que pueda predecir el precio de casas. Veremos qué tan valioso podría ser esto para alguien que vende casas que podría utilizas esa información diariamente.\n","\n","Este dataset surge del UCI Machine Learning Repository con información juntada en 1978 utilizando 14 features de casas de diferentes zonas. La información ha sido preprocesada de la siguiente manera:\n","* 16 casas tenían un MEDV de 50. Lo más seguro es que faltaban valores y fueron eliminaos.\n","* 1 punto tenía un RM de 8.78. Este fue un outlier y por lo tanto fue eliminado.\n","* Los únicos features esenciales que nos interesan por ahora son 'RM', 'LSTAT', 'PTRATIO' y 'MEDV'. Los demas features fueron eliminados\n","* El valor 'MEDV' fue escalado a 35 años de inflación.\n","\n","Ahora explicamos los features"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AagHlcnaB3-C","executionInfo":{"status":"ok","timestamp":1629253715432,"user_tz":300,"elapsed":149,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}},"outputId":"088a8a43-c2d2-4ce2-9565-da3f0660aff4"},"source":["# Importamos librerías\n","import numpy as np\n","import pandas as pd\n","#from sklearn.cross_validation import ShuffleSplit\n","from sklearn.model_selection import ShuffleSplit\n","\n","\n","\n","\n","# Visualizaciones implementadas en visuals.py\n","#import visuals as vs\n","\n","%matplotlib inline\n","\n","# Cargamos dataset y separamos features del label\n","data = pd.read_csv('housing.csv')\n","prices = data['MEDV']\n","features = data.drop('MEDV', axis = 1)\n","    \n","print(\"Boston housing dataset has {} data points with {} variables each.\".format(*data.shape))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["        RM  LSTAT  PTRATIO\n","0    6.575   4.98     15.3\n","1    6.421   9.14     17.8\n","2    7.185   4.03     17.8\n","3    6.998   2.94     18.7\n","4    7.147   5.33     18.7\n","..     ...    ...      ...\n","484  6.593   9.67     21.0\n","485  6.120   9.08     21.0\n","486  6.976   5.64     21.0\n","487  6.794   6.48     21.0\n","488  6.030   7.88     21.0\n","\n","[489 rows x 3 columns]\n","Boston housing dataset has 489 data points with 4 variables each.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sa_Y9HgkB3-W"},"source":["## Exploración\n","\n","En la primera sección del proyecto vamos a investigar la información y darás observaciones de esta. Una práctica fundamental es familiarizarte con la información mediante un proceso explorativo. Los resultados deben estar justificados y no lo podemos hacer con esto.\n","\n","In this first section of this project, you will make a cursory investigation about the Boston housing data and provide your observations. Familiarizing yourself with the data through an explorative process is a fundamental practice to help you better understand and justify your results.\n","\n","### Calculamos estadísticas\n","\n","**TODO** Ahora implementarás código para calcular estadísticas descriptivas de los precios de las casas. NumPy ya ha sido importado, así que lo utilizaremos para hacer estos cálculos. Este paso es importante cuando analicemos los resultados del modelo.\n","\n","Calcula el mínimo, máximo, promedio, mediana y desviación estandar de 'MEDV', el feature que quieres predecir."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"57qOHDIbB3-b","executionInfo":{"status":"ok","timestamp":1629253369950,"user_tz":300,"elapsed":42,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}},"outputId":"4eece3a6-86f8-493e-9a2d-b0d425810d25"},"source":["# Recuerda usar np\n","\n","# TODO: Precio mínimo\n","minimum_price = np.min(prices)\n","\n","# TODO: Precio máximo\n","maximum_price = np.max(prices)\n","\n","# TODO: Promedio\n","mean_price = np.mean(prices)\n","\n","# TODO: Mediana\n","median_price = np.median(prices)\n","\n","# TODO: Desviación estandar\n","std_price = np.std(prices)\n","\n","# Muestra estadística\n","print(\"Statistics for Boston housing dataset:\\n\")\n","print(\"Minimum price: ${}\".format(minimum_price)) \n","print(\"Maximum price: ${}\".format(maximum_price))\n","print(\"Mean price: ${}\".format(mean_price))\n","print(\"Median price ${}\".format(median_price))\n","print(\"Standard deviation of prices: ${}\".format(std_price))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Statistics for Boston housing dataset:\n","\n","Minimum price: $105000.0\n","Maximum price: $1024800.0\n","Mean price: $454342.9447852761\n","Median price $438900.0\n","Standard deviation of prices: $165171.13154429477\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w3EtH-OTB3-j"},"source":["### Pregunta 1 - Observación de features\n","\n","Estamos utlizando 3 features del dataset. Para cada casa:\n","* 'RM' es el promedio de cuartos en las casas del barrio\n","* 'LSTAT' es el porcentaje de trabajadores que se consideran de clase baja.\n","* 'PTRATIO' es el ratio de estudiantes a profesores en primaria y secundaria\n","\n","Usando tu intuición, para cada uno de los features, ¿un incremento en su valor llevaría a un aumento en el valor de 'MEDV' o lo contrario? Justifica tu respuesta para cada uno. Este problema se puede plantear como:¿Esperarías que una casa con 'RM' de 6 valga más o menos que una de 'RM' de 7?"]},{"cell_type":"markdown","metadata":{"id":"CiyaSkuKB3-q"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"01oDZcOUB4F1"},"source":["## Desarrollo del modelo\n","\n","En esta sección, vas a desarrollar las técnicas para que el modelo haga una buena predicción. Evaluar el desempeño de un modelo no es una tarea sencilla, y es algo esencial para tener confianza en el modelo que desarrolles.\n","\n","### Definir métrica de desempeño\n","\n","Hay diferentes métricas para evaluar un modelo. Lo primero es identificar el tipo de problema que es. Siendo un problema de regresión, podemos usar Mean Squared Error, Mean Squared Log Error, R2 Score y otros. Para este proyecto, utilizaremos R2, el coeficiente de determinación, para calcular el desempeño. Es una estadística útil para análisis de regresión y describe qué tan bueno el modelo es haciendo las predicciones. Los valores de R2 van de 0 a 1, que es el porcentaje de la correlación entre valores predecidos y verdaderos al cuadrado. Un modelo de R2 de 0 no es mejor que un modelo que siempre predice el promedio del objetivo, mientras que un modelo con R2 de 1 predice perfectamente la variable objetivo. Si un modelo tiene un valor negativo para R2, significa que el modelo es peor que uno que siempre predice el promedio.\n","\n","En la función ```performance_metric``` en la siguiente celda deberás implementar\n","* Utiliza ```r2_score``` de ```sklearn.metrics``` para hacer el cálculo de desempeño entre y_true y y_predict.\n","* Asigna el valor a la variable score."]},{"cell_type":"code","metadata":{"id":"geEPD4anB4F7","executionInfo":{"status":"ok","timestamp":1629253369953,"user_tz":300,"elapsed":16,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["# TODO: Import 'r2_score'\n","from sklearn.metrics import r2_score\n","\n","def performance_metric(y_true, y_predict):\n","    \"\"\" Calculates and returns the performance score between \n","        true and predicted values based on the metric chosen. \"\"\"\n","    \n","    # TODO: Calculate the performance score between 'y_true' and 'y_predict'\n","    score = r2_score(y_true, y_predict)\n","    \n","    # Return the score\n","    return score"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmRmWWQ1B4GL"},"source":["### Pregunta 2\n","\n","Asume que un dataset contiene 5 puntos y que el modelo hizo las siguientes predicciones:\n","\n","\n","| True Value | Prediction |\n","| :-------------: | :--------: |\n","| 3.0 | 2.5 |\n","| -0.5 | 0.0 |\n","| 2.0 | 2.1 |\n","| 7.0 | 7.8 |\n","| 4.2 | 5.3 |\n","\n","Corre la siguiente celda para calcular el coeficiente de determinación del modelo."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x9KNN6V1B4GP","executionInfo":{"status":"ok","timestamp":1629253370368,"user_tz":300,"elapsed":178,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}},"outputId":"1b673427-0677-4ba5-f87f-a7f7ea2569df"},"source":["# Calculate the performance of this model\n","score = performance_metric([3, -0.5, 2, 7, 4.2], [2.5, 0.0, 2.1, 7.8, 5.3])\n","print(\"Model has a coefficient of determination, R^2, of {:.3f}.\".format(score))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Model has a coefficient of determination, R^2, of 0.923.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hCTMi5FrB4GS"},"source":["¿Consideras que este modelo ha capturado la variación del target exitosamente o no? ¿Por qué?\n","\n","Hint\n","- R2 de 0 significa que la variable dependiente no puede ser predecida de la independiente.\n","- R2 de 1 significa que si puede.\n","- Un R2 de 0.40 significa que 40% de la varianza en Y es predecible de X."]},{"cell_type":"markdown","metadata":{"id":"hYQn1DEtB4GU"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"W97eUKi_B4GW"},"source":["### Barajar y separar data\n","\n","Ahora, la siguiente tarea es separar en training y testing. Normalmente, la información se baraja aleatoriamente en este paso para quitar cualquier bias de tener el dataset ordenado.\n","\n","En la siguiente celda, implementa lo siguiente\n","* Usa `train_test_split` de `sklearn.cross_validation` para barajar y separar `features` y `prices` en training y testing.\n","    - Separa la información con 80% en training."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":370},"id":"aKpIrlSZB4Gf","executionInfo":{"status":"error","timestamp":1629253370441,"user_tz":300,"elapsed":243,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}},"outputId":"069ff0d7-38a6-45bc-d197-d3b1523568b8"},"source":["# TODO: Import 'train_test_split'\n","from sklearn.cross_validation import train_test_split\n","\n","# TODO: Shuffle and split the data into training and testing subsets\n","X_train, X_test, y_train, y_test = train_test_split(features, prices, test_size = 0.2) \n","\n","print(\"Training and testing split was successful.\")"],"execution_count":13,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-c1f1c46177c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Import 'train_test_split'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# TODO: Shuffle and split the data into training and testing subsets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","metadata":{"id":"EOuQySGMB4Gh"},"source":["### Pregunta 3\n","¿Cuál es el beneficio de separar un dataset en testing y training para un algoritmo de aprendizaje?"]},{"cell_type":"markdown","metadata":{"id":"6dx_xZ0aB4Gj"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"MlzF-7N3B4Gl"},"source":["## Analizando Desempeño\n","En esta tercera sección, mirarás el desempeño de diferentes modelos en varios pedazos de training data. Adicionalmente, mirarás un algoritmo particular que tiene un parámetros `max_depth` para ver cómo la complejidad del modelo afecta su desempeño. Graficar el desempeño del modelo en varios criterios puede beneficiar el proceso de analizar tu modelo.\n","\n","### Curvas de Aprendizaje\n","La siguiente celda produce cuatro gráficas para un árbol de decisiones con diferente profundidad. Cada gráfica visualiza las curvas de curva de aprendizaje tanto en la información de entrenamiento y de testing mientras se van dando más ejemplos. La zona sombreada es la incertidumbre de la curva medida con la desviación estandar. El score se calcula con R2."]},{"cell_type":"code","metadata":{"id":"o9dV5jtIB4Gs","executionInfo":{"status":"aborted","timestamp":1629253370371,"user_tz":300,"elapsed":166,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["vs.ModelLearning(features, prices)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztaFOeXpB4Gv"},"source":["### Pregunta 4\n","* Elige uno de las gráficas de arriba y di cuál es su profundidad máxima\n","* ¿Qué pasa con la curva de entrenamiento y con la curva de testing cuando se dan más ejemplos?\n","* ¿Ayudaría si hubieran más puntos de entrenamiento?\n","\n","**Hint:** ¿Las curvas convergen en algún score particular?"]},{"cell_type":"markdown","metadata":{"id":"O4sPF8NoB4Gy"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"DVlhJMwPB4Gz"},"source":["### Curvas de complejidad\n","\n","La siguiente celda produce una gráfica para un modelo de árbol de decisión que ha sido entrenado y validado con la información de entrenamiento con diferentes profundidades. Una curva es entrenamiento y otra es validación. Se utiliza `performance_metric` para medir el score."]},{"cell_type":"code","metadata":{"id":"ZjPC8S5jB4G4","executionInfo":{"status":"aborted","timestamp":1629253370410,"user_tz":300,"elapsed":204,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["vs.ModelComplexity(X_train, y_train)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zW3e81ZsB4G6"},"source":["### Pregunta 5\n","* Cuando el modelo tiene un maximum depth de 1, ¿el modelo sufre de bias o de variance?\n","* ¿Y Cuando el modelo tiene un maximum depth de 10?\n","* ¿Qué pistas visuales en la gráfica soportan tu conclusión?"]},{"cell_type":"markdown","metadata":{"id":"JKTieNq8B4G8"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"Xch2XMDtB4G8"},"source":["### Pregunta 6\n","* ¿Cuál depth generaliza mejor para información que no ha visto?\n","* ¿Cuál es tu intuición para esta respuesta?"]},{"cell_type":"markdown","metadata":{"id":"n2RdpYlcB4G9"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"encspFJmB4HA"},"source":["## Evaluando desempeño\n","Es hora de construir un modelo y optimizarlo."]},{"cell_type":"markdown","metadata":{"id":"YKCdcLseB4HB"},"source":["### Pregunta 7\n","* ¿Qué es Grid Search?\n","* ¿Cómo se aplica para optimizar un algoritmo de aprendizaje?\n","* ¿Cuál es el fin de este método?\n","* ¿Puedes dar un ejemplo?"]},{"cell_type":"markdown","metadata":{"id":"DO3qbTwUB4HE"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"lF_lvk4tB4HF"},"source":["### Implementación del modelo\n","\n","Vamos a combinar todo lo que hemos visto para construir y entrenar un modelo que usa un **árbol de decisiones**. Para asegurarnos que el modelo está optimizado, utilizaremos una técnica llamada grid search para optimizar el `max_depth` del árobl de decisiones. Este parámetro puede ser pensado como cuántas preguntas debe hacer el algoritmo para hacer una predicción. \n","\n","Adicionalmente, utilizarás `ShuffleSplit()`como una alternativa de cross-validation. Esa parte ya está implementada. Esta creará `n_splits` conjuntos barajeados, y, para cada uno, 20% de la información será usada como set de validación. \n","\n","Necesitarás implementar lo siguiente\n","- Utiliza [`DecisionTreeRegressor`](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) de `sklearn.tree` para crear el clasificador.\n","- Crea un diccionario para `max_depth` donde los valores vayan de 1 a 10.\n","- Crea un objeto de scoring [`make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html) de `sklearn.metrics`\n","    - Envía `performance_metric` como parámetro\n","- Usa [`GridSearchCV`](http://scikit-learn.org/0.17/modules/generated/sklearn.grid_search.GridSearchCV.html) from `sklearn.grid_search` para crear el objeto de Grid Search"]},{"cell_type":"code","metadata":{"id":"lenlDJ77B4HG","executionInfo":{"status":"aborted","timestamp":1629253370426,"user_tz":300,"elapsed":219,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["# TODO: Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import make_scorer\n","from sklearn.tree import DecisionTreeRegressor\n","\n","def fit_model(X, y):\n","    \"\"\" Performs grid search over the 'max_depth' parameter for a \n","        decision tree regressor trained on the input data [X, y]. \"\"\"\n","    \n","    # Create cross-validation sets from the training data\n","    cv_sets = ShuffleSplit(X.shape[0], n_iter = 10, test_size = 0.20, random_state = 0)\n","\n","    # TODO: Create a decision tree regressor object\n","    regressor = DecisionTreeRegressor()\n","\n","    # TODO: Create a dictionary for the parameter 'max_depth' with a range from 1 to 10\n","    params = {'max_depth':range(1,11)}\n","\n","    # TODO: Transform 'performance_metric' into a scoring function using 'make_scorer' \n","    scoring_fnc = make_scorer(performance_metric)\n","\n","    # TODO: Create the grid search cv object --> GridSearchCV()\n","    # Make sure to include the right parameters in the object:\n","    # (estimator, param_grid, scoring, cv) which have values 'regressor', 'params', 'scoring_fnc', and 'cv_sets' respectively.\n","    grid = GridSearchCV(regressor, params, scoring_fnc, cv=cv_sets)\n","\n","    # Fit the grid search object to the data to compute the optimal model\n","    grid = grid.fit(X, y)\n","\n","    # Return the optimal model after fitting the data\n","    return grid.best_estimator_"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwLWqKJ2B4HH"},"source":["### Pregunta 9\n","\n","* Corre la siguiente celda para ver conseguir el modelo óptimo\n","* ¿Cuál es la profundidad óptima para el modelo? ¿Cómo se compara con tu respuesta de la pregunta 6?"]},{"cell_type":"code","metadata":{"id":"Ja_V0U5_B4HI","executionInfo":{"status":"aborted","timestamp":1629253370430,"user_tz":300,"elapsed":222,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["# Fit the training data to the model using grid search\n","reg = fit_model(X_train, y_train)\n","\n","# Produce the value for 'max_depth'\n","print(\"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth']))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TQZBFeeVB4HJ"},"source":["**Respuesta**"]},{"cell_type":"markdown","metadata":{"id":"g3y7Xpq7B4HK"},"source":["### Pregunta 10 \n","\n","Imagina que un agente quiere usar el modelo para ayudar a sus clientes diciendo a qué precio deberían vender. Tiene la siguiente info de sus clientes:\n","\n","| Feature | Client 1 | Client 2 | Client 3 |\n","| :---: | :---: | :---: | :---: |\n","| Total number of rooms in home | 5 rooms | 4 rooms | 8 rooms |\n","| Neighborhood poverty level (as %) | 17% | 32% | 3% |\n","| Student-teacher ratio of nearby schools | 15-to-1 | 22-to-1 | 12-to-1 |\n","\n","\n","* ¿A qué precio recomendarías vender la casa a cada cliente?\n","* ¿Estos precios son razonables para los features?\n","\n","**Hint** Para la segunda pregunta, usa las estadísticas calculadas al inicio. "]},{"cell_type":"code","metadata":{"id":"dmwmS-SXB4HK","executionInfo":{"status":"aborted","timestamp":1629253370433,"user_tz":300,"elapsed":225,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["# Produce a matrix for client data\n","client_data = [[5, 17, 15], # Client 1\n","               [4, 32, 22], # Client 2\n","               [8, 3, 12]]  # Client 3\n","\n","# Show predictions\n","for i, price in enumerate(reg.predict(client_data)):\n","    print(\"Predicted selling price for Client {}'s home: ${:,.2f}\".format(i+1, price))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X1pPXcxCB4HM"},"source":["### Sensitividad\n","Un modelo óptimo no es, necesariamente, un modelo robusto. A veces, un modelo puede ser muy complejo o simple. A veces, el algoritmo de aprendizaje no es el apropiado. Otras veces, la información puede tener mucho ruido o tener pocos ejemplos para que un modelo aprenda.\n","\n","Corre la siguiente celda para correr `fit_model` 10 veces con diferentes conjuntos para ver si cambian las predicciones para los clientes."]},{"cell_type":"code","metadata":{"id":"drnPfr7LB4HM","executionInfo":{"status":"aborted","timestamp":1629253370435,"user_tz":300,"elapsed":226,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":["vs.PredictTrials(features, prices, fit_model, client_data)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JKY3qcdTB4HR"},"source":["### Pregunta 11\n","\n","* En unas oraciones, explica porque el modelo construido debería ser utilizado o no en la vida real.\n","\n","**Hint** Mira los rangos de precios calculados. Algunas buenas preguntas son:\n","    - ¿Qué tan relevante es la info de 1978? ¿Qué tan importante es la inflación?\n","    - ¿Los features que usamos son suficienes para predecir el precio de una casa?\n","    - ¿El modelo es robusto para hacer predicciones consistentes?\n","    - ¿Lo recolectado en una ciudad urbana aplicaría en una ciudad rural?\n","    - ¿Es justo decidir el precio de una casa individual a partir de las características del barrio?"]},{"cell_type":"code","metadata":{"id":"s1w_t0JtB4HS","executionInfo":{"status":"aborted","timestamp":1629253370439,"user_tz":300,"elapsed":229,"user":{"displayName":"Enrique Díaz","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj-9c_gVbdOrh1TPwn7g1oKw5TR3WqeMqVcwrTf9g=s64","userId":"17549734348715053613"}}},"source":[""],"execution_count":null,"outputs":[]}]}